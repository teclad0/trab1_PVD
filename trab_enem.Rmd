---
title: "trab1"
output: html_document
date: '2022-04-01'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Descrição do conjunto

O conjunto contém os dados de realização do Exame Nacional do Ensino Médio, aplicado nos dias 17 e 24 de janeiro de 2021 (por conta da pandemia de coronavírus). Também houve, pela primeira vez, a aplicação digital da prova, em 31 de janeiro e 07 de fevereiro, além da segunda aplicação para Pessoas Privadas de Liberdade, em 24 e 25 de fevereiro.

No total, existem 76 atributos e 5783109 linhas, contemplando todas as aplicações da inscrição e prova.

[TODO: DECIDIR SE VAMOS COLOCAR TODOS OS 76 ATRIBUTOS AQUI OU APENAS ALGUNS]

Os dados foram obtidos através da plataforma oficial do Governo Federal e podem ser acessados em: <https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados/enem>

# Inicialização

```{r}
library(tidyverse)
library(data.table)
```
# Importação

Considerando que o dataset completo possui cerca de 2GB de dados, foram carregadas apenas as 2.000.000 primeiras linhas, já que o dataset inteiro pode não caber em memória em diversas máquinas.

```{r}
file <- 'enem/DADOS/MICRODADOS_ENEM_2020.csv'
enem.df <- fread(input=file,
           integer64='character',
           encoding = "Latin-1",
           quote = FALSE,
           na.strings = "",
           nrows=1000000)

enem.df
```

# Pré-Processamento

## Verificação de possíveis atributos redundantes

Para o cálculo de covariância, é necessário dropar colunas com valores constantes e tratar casos com desvio padrão 0 e com valores NA. [ x ]TODO: variaveis nominais

### Atributos numéricos
```{r}
# Tirar o nu_inscricao?
enem.df_numeric <- as.data.frame(enem.df %>% select(where(is.numeric), -NU_ANO))

cor_fun <- function(x, y) {
  val <- tryCatch(cor(x, y), error = function(e) e, warning = function(w) w)
  if (any(class(val) %in% c("simpleWarning", "warning"))) {
    return(mean(x))
  } else {
    return(val)
  }
}

medidas <- function(vetor1, vetor2) {
  corr_medida <- cor_fun(vetor1, vetor2)
  det_medida <- cor_fun(vetor1, vetor2)^2
  lista_medidas <-
    list("correlacao" = corr_medida, "determinacao" = det_medida)
  lista_medidas
}

calculo_redundante <- function(dados){
  resultado <- tibble(
  colu1= character(),
  colu2= character(),
  r= numeric(),
  R2=numeric()
  )
  for (col1 in colnames(dados)) {
    for (col2 in colnames(dados)) {
      if (col1 == col2) {
        next
      }
      li_med <- medidas(dados[, col1], dados[, col2])


      # Retornar apenas atributos com valores relevantes
      if (!is.na(li_med$correlacao) & !is.na(li_med$determinacao)) {
        if (li_med$correlacao > 0.7 |
          li_med$correlacao < -0.7 |
          li_med$determinacao > 0.7) {
          resultado <- add_row(resultado,
            colu1 = col1, colu2 = col2,
            r = li_med$correlacao,
            R2 = li_med$determinacao
          )
        }
      }
    }
  }
  resultado <- resultado[
    !duplicated(
      apply(resultado, 1, function(x) paste(sort(x), collapse = ""))
    ),
  ]

  resultado <- resultado %>% arrange(desc(r), desc(R2))
  return(resultado)
}

resultado <- calculo_redundante(enem.df_numeric)
resultado

```

Através do resultado, é possível observar que os atributos TP_PRESENCA_CH e TP_PRESENCA_LC, TP_PRESENCA_MT e TP_PRESENCA_CN possuem r e R² iguais a um. Isso significa que todos os valores são exatamente iguais. Essa situação faz sentido pois as provas de linguagens e códigos e ciências humanas, e ciências da natureza e matemática são realizadas no mesmo dia.

Além disso, os atributos CO_MUNICIPIO_PROVA e CO_UF_PROVA possuem um valor bem próximo de 1, sendo 0.99 para o r e 0.99 para o R². Isso se deve ao fato de que o código do município sempre contém o código da UF em que a prova foi realizada.

Portanto, para esses atributos a decisão é remover um de cada par pois seus valores são exatamente iguais ou bastante próximos.

[ ] TODO: DROPAR OS ATRIBUTOS CITADOS e ANO
//Pode-se observar que o é útil para identificar padrões nos dados (e.g., como os dados de um atributo “segue” os dados de
outro atributo), enquanto o é interessante para mensurar a compatibilidade entre os valores.

### Atributos categoricos

```{r}
enem.df_list <- enem.df %>%
  select(where(is.character)) %>%
  group_by(Q007) %>%
  slice_head(n=500) %>%
  group_split(.keep=FALSE) 

head(enem.df_list)

```


```{r}

chisq <- function(dados){
  resultado <- tibble(
  colu1= character(),
  colu2= character(),
  x2 = numeric(),
  p_value= numeric()
   )
  
   for (col1 in colnames(dados)) {
    for(col2 in colnames(dados)){
      if (col1 == col2 ) {
        next
      }
      
      #print(paste(col1, col2))
      chisq <- chisq.test(unlist(dados[,col1]), unlist(dados[,col2]), simulate.p.value = TRUE)
      p <-  chisq$p.value
      xsq <- chisq$statistic
      
      resultado <- add_row(resultado, colu1=col1, colu2=col2, x2= xsq, p_value=p)
      
      }
      }
  resultado<- resultado[!duplicated(apply(resultado,1,function(x) paste(sort(x),collapse=''))),]
  resultado <- resultado %>% arrange(p_value)
  resultado
}

rlt_chisq_1 <- chisq(enem.df_list[[2]])
rlt_chisq_1


```

[] TODO **Realizar o teste para cada subconjunto de dados e dividir por categoria**

// os atributos de TX_GABARITO_* se repetem, pois eh uma taxa de gabarito pra cada tipo de prova, por volta de 14 tipos de provas, ao inves de ter um vetor enorme talvez substituir por um codigo ou categoria

## Normalização

A normalização será realizada nos atributos NU_NOTA_CH e NU_NOTA_MT que representam, respectivamente, a nota da prova de ciências humanas e a nota de redação. 
O conjunto de dados possui diversos atributos sem significado semantico(n sei se eh essa a palavra), que apresentam um significado específico, como código de provas e código de municipio.

### Aplicação no atributos NU_NOTA_CH e NU_NOTA_MT
No bloco abaixo, as funções z score e min-max são aplicadas nos atributos escolhidos
e os resultados são adicionados a um novo conjunto, chamado *enem.df_numeric_norm*,  derivado do conjunto original.
```{r}
head(enem.df_numeric,50)
options(scipen = 999) 

z_score_norm <- function(x) {
  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
}
min_max_norm <- function(x, min = 0, max = 1) {
  num <- (x - min(x, na.rm = TRUE)) * (max - min)
  denom <- max(x, na.rm = TRUE) - min(x, na.rm = TRUE)

  min + num / denom
}

NU_NOTA_CH_normz <- z_score_norm(enem.df$NU_NOTA_CH)
NU_NOTA_CH_norm01 <- min_max_norm(enem.df$NU_NOTA_CH)
NU_NOTA_MT_normz <- z_score_norm(enem.df$NU_NOTA_MT)
NU_NOTA_MT_norm01 <- min_max_norm(enem.df$NU_NOTA_MT)

# Colocar do numerico pq vai precisar rodar o r e R²
enem.df_numeric_norm <- enem.df_numeric %>%
  select(-NU_NOTA_CH, -NU_NOTA_MT) %>%
  mutate(
    NU_NOTA_CH_normz, NU_NOTA_CH_norm01,
    NU_NOTA_MT_normz, NU_NOTA_MT_norm01
  )


head(enem.df_numeric_norm)
summary(enem.df_numeric)
summary(enem.df_numeric_norm)
```

A seguir são realizado teste para analisar os efeitos da normalização com os 
atributos redundantes.

### Efeitos normalização 
```{r}

# Teste de redundancia dos atributos numéricos normalizados no conjunto 

cor_fun <- function(x, y) {
  val <- tryCatch(
    cor(x, y, use = "complete.obs"),
    error = function(e) e,
    warning = function(w) w
  )
  if (any(class(val) %in% c("simpleWarning", "warning"))) {
    return(mean(x))
  } else {
    return(val)
  }
}

calculo_redundante_norm <- function(dados) {
  resultado <- tibble(
    colu1 = character(),
    colu2 = character(),
    r = numeric(),
    R2 = numeric()
  )

  # for (col1 in colnames(dados)) {
  for (col1 in
    c(
      "NU_NOTA_CH_normz", "NU_NOTA_CH_norm01",
      "NU_NOTA_MT_normz", "NU_NOTA_MT_norm01"
  )) {
    for (col2 in colnames(dados)) {
      if (col1 == col2) {
        next
      }

      li_med <- medidas(dados[, col1], dados[, col2])


      if (!is.na(li_med$correlacao) & !is.na(li_med$determinacao)) {
        resultado <- add_row(resultado,
          colu1 = col1, colu2 = col2,
          r = li_med$correlacao, R2 = li_med$determinacao
        )
      }
    }
  }
  resultado <- resultado[
    !duplicated(
      apply(resultado, 1, function(x) paste(sort(x), collapse = ""))
    ),
  ]
  resultado <- resultado %>% arrange(desc(r), desc(R2))
  return(resultado)

  }

rlt_redun_norms <- calculo_redundante_norm(enem.df_numeric_norm)
rlt_redun_norms

```

Com o df original
```{r}
# Teste com atributos numéricos realizado no conjunto com os atributos originais, apenas observando o comportamento em comparação aos atributos escolhidos

calculo_redundante_notas <- function(dados) {
  resultado <- tibble(
    colu1 = character(),
    colu2 = character(),
    r = numeric(),
    R2 = numeric()
  )

  for (col1 in c("NU_NOTA_CH", "NU_NOTA_MT")) {
    for (col2 in colnames(dados)) {
      if (col1 == col2) {
        next
      }

      li_med <- medidas(dados[, col1], dados[, col2])
      if (!is.na(li_med$correlacao) & !is.na(li_med$determinacao)) {
        resultado <- add_row(resultado,
          colu1 = col1, colu2 = col2,
          r = li_med$correlacao, R2 = li_med$determinacao
        )
      }
    }
  }
  resultado <- resultado[
    !duplicated(
      apply(resultado, 1, function(x) paste(sort(x), collapse = ""))
    ),
  ]
  resultado <- resultado %>% arrange(desc(r), desc(R2))
  return(resultado)
}

rlt_redun_original <- calculo_redundante_notas(enem.df_numeric)
rlt_redun_original

```

[ ] TODO: analisar e comparar as tabelas produzidas, rlt_redun_norms e rlt_redun_original se os coeficientes estão parecidos

## Manipulação de dados faltantes

Primeiramente, vamos analisar o nosso dataset para encontrar quais e quantos são os dados faltantes:

```{r}
# conta a quantidade de dados NA
na_count <- colSums(is.na(enem.df)) %>%
  as.data.frame()

names(na_count) <- c("count")

na_count <- filter(na_count, count > 0) %>%
  mutate(percentage = count * 100 / nrow(enem.df)) %>% arrange(desc(count))

na_count
```

Apesar de incrivelmente alto, esse número condiz com os dados do INEP, que afirma que em torno de 48% dos inscritos não compareceram à prova. Vale lembrar que essa aplicação ocorreu em janeiro de 2021, época em que a pandemia de coronavírus ainda era severa no Brasil.

[ ] TODO Igor: completar inputação de dados faltantes 

