---
title: "trab1"
output: html_document
date: '2022-04-01'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Descrição do conjunto

O conjunto contém os dados de realização do Exame Nacional do Ensino Médio, aplicado nos dias 17 e 24 de janeiro de 2021 (por conta da pandemia de coronavírus). Também houve, pela primeira vez, a aplicação digital da prova, em 31 de janeiro e 07 de fevereiro, além da segunda aplicação para Pessoas Privadas de Liberdade, em 24 e 25 de fevereiro.

No total, existem 76 atributos e 5783109 linhas, contemplando todas as aplicações da inscrição e prova.

[TODO: DECIDIR SE VAMOS COLOCAR TODOS OS 76 ATRIBUTOS AQUI OU APENAS ALGUNS]

Os dados foram obtidos através da plataforma oficial do Governo Federal e podem ser acessados em: <https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados/enem>

# Inicialização

```{r}
library(tidyverse)
library(data.table)
library(rcompanion)
library(lsr)
library(vcd)
library(outliers)
library(EnvStats)
library(DescTools)
library(Hmisc)
library(VIM)

library(devtools)
install_github("vqv/ggbiplot")
library(ggbiplot)
```

# Importação

Considerando que o dataset completo possui cerca de 2GB de dados, foram carregadas apenas as 200.000 primeiras linhas, já que o dataset inteiro pode não caber em memória em diversas máquinas e torna o processamento extramente custoso.

```{r}
file <- 'enem/DADOS/MICRODADOS_ENEM_2020.csv'
enem.df <- fread(input=file,
           integer64='character',
           encoding = "Latin-1",
           quote = FALSE,
           na.strings = "",
           nrows=200000)

head(enem.df)
```

# Pré-Processamento

## Verificação de possíveis atributos redundantes

Para o cálculo de covariância, é necessário dropar colunas com valores constantes e tratar casos com desvio padrão 0 e com valores NA.

### Atributos numéricos

```{r}
# Tirar o nu_inscricao?
enem.df_numeric <- as.data.frame(enem.df %>% select(where(is.numeric), -NU_ANO))

cor_fun <- function(x, y) {
  val <- tryCatch(cor(x, y), error = function(e) e, warning = function(w) w)
  if (any(class(val) %in% c("simpleWarning", "warning"))) {
    return(mean(x))
  } else {
    return(val)
  }
}

medidas <- function(vetor1, vetor2) {
  corr_medida <- cor_fun(vetor1, vetor2)
  det_medida <- cor_fun(vetor1, vetor2)^2
  lista_medidas <-
    list("correlacao" = corr_medida, "determinacao" = det_medida)
  lista_medidas
}

calculo_redundante <- function(dados){
  resultado <- tibble(
  colu1= character(),
  colu2= character(),
  r= numeric(),
  R2=numeric()
  )
  for (col1 in colnames(dados)) {
    for (col2 in colnames(dados)) {
      if (col1 == col2) {
        next
      }
      li_med <- medidas(dados[, col1], dados[, col2])


      # Retornar apenas atributos com valores relevantes
      if (!is.na(li_med$correlacao) & !is.na(li_med$determinacao)) {
        if (li_med$correlacao > 0.7 |
          li_med$correlacao < -0.7 |
          li_med$determinacao > 0.7) {
          resultado <- add_row(resultado,
            colu1 = col1, colu2 = col2,
            r = li_med$correlacao,
            R2 = li_med$determinacao
          )
        }
      }
    }
  }
  resultado <- resultado[
    !duplicated(
      apply(resultado, 1, function(x) paste(sort(x), collapse = ""))
    ),
  ]

  resultado <- resultado %>% arrange(desc(r), desc(R2))
  return(resultado)
}

resultado <- calculo_redundante(enem.df_numeric)
resultado

```

Através do resultado, é possível observar que os atributos TP_PRESENCA_CH e TP_PRESENCA_LC, TP_PRESENCA_MT e TP_PRESENCA_CN possuem r e R² iguais a um. Isso significa que todos os valores são exatamente iguais. Essa situação faz sentido pois as provas de linguagens e códigos e ciências humanas, e ciências da natureza e matemática são realizadas no mesmo dia, assim como as outras presenças, pois é bem provavél que se a pessoa foi para o primeiro dia de prova ela também vai para o segundo dia de prova, senão a prova é anulada.

Além disso, os atributos CO_MUNICIPIO_PROVA e CO_UF_PROVA possuem um valor bem próximo de 1, sendo 0.99 para o r e 0.99 para o R². Isso se deve ao fato de que o código do município sempre contém o código da UF em que a prova foi realizada.

```{r}
head(enem.df$CO_MUNICIPIO_PROVA)
head(enem.df$CO_UF_PROVA)

```

### Atributos categóricos

[ ]explicar rapidamente o coeficiente cramer

```{r}
enem.df_character <- enem.df %>%
  select(where(is.character), -NU_INSCRICAO, -TX_RESPOSTAS_CN, -TX_RESPOSTAS_CH, -TX_RESPOSTAS_LC, -TX_RESPOSTAS_MT) 


cramers_v <- function(dados){
  rslt <- tibble(
  colu1= character(),
  colu2= character(),
  cramer = numeric()
   )
  
   for (col1 in colnames(dados)) {
    for(col2 in colnames(dados)){
      if (col1 != col2) {
        
      #print(paste(col1, col2))
      
      #c <- cv(unlist(dados[,..col1]), unlist(dados[,..col2]))
      #c <- cv(unlist(dados[,col1]), unlist(dados[,col2]))
      #print(c)
      c <- CramerV(unlist(dados[,..col1]), unlist(dados[,..col2]), useNA="ifany")
            if( c > 0.7){
              rslt <- add_row(rslt, colu1=col1, colu2=col2, cramer=c)}
      }
      }
      }
  rslt<- rslt[!duplicated(apply(rslt,1,function(x) paste(sort(x),collapse=''))),]
  rslt <- rslt %>% arrange(desc(cramer))
  rslt
}

rlt_cramer <-  cramers_v(enem.df_character)
rlt_cramer
```

Observa-se no resultado que os atributos TX_GABARITO possuem o valor de coeficiente exatamente 1, isso se dá pois esse atributo é um vetor com as respostas de cada tipo prova e as provas de ciências da natureza e matemática são realizadas juntas, assim como as provas de linguagens e códigos e ciências humanas.

### Conclusão

Os coeficientes utilizados nos ajudaram a entender os relacionamentos e associações existentes nesse conjunto de dados, dessa forma encontramos atributos que são redundantes e podem ser removidos sem prejudicar o conjunto de dados. São esses atributos:

-   TP_PRESENCA_CH mesma compatibilidade com TP_PRESENCA_MT, TP_PRESENCA_CN e TP_PRESENCA_LC
-   CO_MUNICIPIO_PROVA contém CO_UF_PROVA
-   TX_GABARITO_CN mesma compatibilidade com TX_GABARITO_MT\
-   TX_GABARITO_CH mesma compatibiilidade com TX_GABARITO_LC\
-   NO_MUNICIPIO_PROVA contém SG_UF_PROVA\
-   NO_MUNICIPIO_ESC contém SG_UF_ESC

[ ] TODO: DROPAR OS ATRIBUTOS CITADOS e ANO

## Normalização

A normalização será realizada nos atributos NU_NOTA_CH e NU_NOTA_MT que representam, respectivamente, a nota da prova de ciências humanas e a nota de redação. O conjunto de dados possui diversos atributos sem significado semantico(n sei se eh essa a palavra), que apresentam um significado específico, como código de provas e código de municipio.

### Aplicação no atributos NU_NOTA_CH e NU_NOTA_MT

No bloco abaixo, as funções z score e min-max são aplicadas nos atributos escolhidos e os resultados são adicionados a um novo conjunto, chamado *enem.df_numeric_norm*, derivado do conjunto original.

```{r}
head(enem.df_numeric,50)
options(scipen = 999) 

z_score_norm <- function(x) {
  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
}
min_max_norm <- function(x, min = 0, max = 1) {
  num <- (x - min(x, na.rm = TRUE)) * (max - min)
  denom <- max(x, na.rm = TRUE) - min(x, na.rm = TRUE)

  min + num / denom
}

NU_NOTA_CH_normz <- z_score_norm(enem.df$NU_NOTA_CH)
NU_NOTA_CH_norm01 <- min_max_norm(enem.df$NU_NOTA_CH)
NU_NOTA_MT_normz <- z_score_norm(enem.df$NU_NOTA_MT)
NU_NOTA_MT_norm01 <- min_max_norm(enem.df$NU_NOTA_MT)

# Colocar do numerico pq vai precisar rodar o r e R²
enem.df_numeric_norm <- enem.df_numeric %>%
  select(-NU_NOTA_CH, -NU_NOTA_MT) %>%
  mutate(
    NU_NOTA_CH_normz, NU_NOTA_CH_norm01,
    NU_NOTA_MT_normz, NU_NOTA_MT_norm01
  )


head(enem.df_numeric_norm)
```

A seguir são realizados testes para analisar os efeitos da normalização com os atributos redundantes.

### Efeitos normalização

```{r}

# Teste de redundância dos atributos numéricos normalizados no conjunto 

cor_fun <- function(x, y) {
  val <- tryCatch(
    cor(x, y, use = "complete.obs"),
    error = function(e) e,
    warning = function(w) w
  )
  if (any(class(val) %in% c("simpleWarning", "warning"))) {
    return(mean(x))
  } else {
    return(val)
  }
}

calculo_redundante_norm <- function(dados) {
  resultado <- tibble(
    colu1 = character(),
    colu2 = character(),
    r = numeric(),
    R2 = numeric()
  )

  # for (col1 in colnames(dados)) {
  for (col1 in
    c(
      "NU_NOTA_CH_normz", "NU_NOTA_CH_norm01",
      "NU_NOTA_MT_normz", "NU_NOTA_MT_norm01"
  )) {
    for (col2 in colnames(dados)) {
      if (col1 == col2) {
        next
      }

      li_med <- medidas(dados[, col1], dados[, col2])

      if (!is.na(li_med$correlacao) & !is.na(li_med$determinacao)) {
        resultado <- add_row(resultado,
          colu1 = col1, colu2 = col2,
          r = li_med$correlacao, R2 = li_med$determinacao
        )
      }
    }
  }
  resultado <- resultado[
    !duplicated(
      apply(resultado, 1, function(x) paste(sort(x), collapse = ""))
    ),
  ]
  resultado <- resultado %>% arrange(desc(r), desc(R2))
  return(resultado)

  }

rlt_redun_norms <- calculo_redundante_norm(enem.df_numeric_norm)
head(rlt_redun_norms)

```

Testes realizados com o dataset original

```{r}
# Teste com atributos numéricos realizado no conjunto com os atributos originais, apenas observando o comportamento em comparação aos atributos escolhidos

calculo_redundante_notas <- function(dados) {
  resultado <- tibble(
    colu1 = character(),
    colu2 = character(),
    r = numeric(),
    R2 = numeric()
  )

  for (col1 in c("NU_NOTA_CH", "NU_NOTA_MT")) {
    for (col2 in colnames(dados)) {
      if (col1 == col2) {
        next
      }

      li_med <- medidas(dados[, col1], dados[, col2])
      if (!is.na(li_med$correlacao) & !is.na(li_med$determinacao)) {
        resultado <- add_row(resultado,
          colu1 = col1, colu2 = col2,
          r = li_med$correlacao, R2 = li_med$determinacao
        )
      }
    }
  }
  resultado <- resultado[
    !duplicated(
      apply(resultado, 1, function(x) paste(sort(x), collapse = ""))
    ),
  ]
  resultado <- resultado %>% arrange(desc(r), desc(R2))
  return(resultado)
}

rlt_redun_original <- calculo_redundante_notas(enem.df_numeric)
head(rlt_redun_original)

```

### Conclusão

Concluí-se que o uso das normalizações manteve o mesmo significado dos coeficientes quando comparado ao uso dos dados originais

## Manipulação de dados faltantes

Primeiramente, vamos analisar o nosso dataset para encontrar quais e quantos são os dados faltantes:

```{r}
# conta a quantidade de dados NA
na_count <- colSums(is.na(enem.df)) %>%
  as.data.frame()

names(na_count) <- c("count")

na_count <- filter(na_count, count > 0) %>%
  mutate(percentage = count * 100 / nrow(enem.df)) %>%
  select(percentage) %>%
  arrange(desc(percentage))

na_count
```

[ TODO Igor: trocar esse método por um hotdeck ou knn, tá muito ruim]

Apesar de incrivelmente alto, esse número condiz com os dados do INEP, que afirma que em torno de 48% dos inscritos não compareceram à prova. Vale lembrar que essa aplicação ocorreu em janeiro de 2021, época em que a pandemia de coronavírus ainda era severa no Brasil. Ainda assim, uma quantidade muito significativa de 78% dos dados relacionados ao local de aplicação não estão disponíveis, não sabemos o motivo.  
Como a maioria desses dados serve para identificação do local de aplicação, vamos focar na imputação do questionário socioeconômico, já que há linhas onde as pessoas compareceram à prova mas não responderam ao questionário. Dessa forma, também pretendemos reduzir um possível enviesamento ao imputar uma quantidade tão grande de dados.  
Utilizaremos as questões de 1 a 6 para realizar o tratamento de dados faltantes. Por serem atributos que servem para identificar questões sociais e econômicas de um indivíduo, entendemos que uma abordagem baseada em tendência central pode não ser tão precisa, considerando a complexidade das análises que podem ser feitas a partir do dataset.  
Sendo assim, vamos utilizar a imputação `aregImpute` do pacote Hmisc apresentado na disciplina, que utiliza média preditiva e pode trazer melhores resultados por se basear em outros atributos além dos em questão.  


```{r}
#aregImpute(~ Q001 + Q002 + Q003 + Q004 + Q005 + Q006,
#           data = enem.df, n.impute = 5)
```
Como podemos observar, as medidas de R² para os valores imputados ficaram entre 50 a 56%, o que não é o melhor valor possível, mas pode ser considerado. Outras tentativas válidas seriam imputação por KNN ou regressão linear, porém, dado o tamanho do dataset, não conseguimos executá-las.  


## Manipulação de dados ruídosos e outliers

```{r}
ruidos_outliers <- function(dados) {
  resultado <- tibble(
    atr = character(),
    grubb = numeric(),
    dixon = numeric(),
    rosner = numeric()
  )

  for (col1 in colnames(dados)) {
    print(col1)
    g <- grubbs.test(unlist(dados[,col1]))$p.value
    d <- 0
    #d <- dixon.test(unlist(dados[,col1]))
    r <- rosnerTest(unlist(dados[,col1]))$n.outliers
    
    resultado <- add_row(atr= col1, grubb= g, dixon= d, rosner= r)
  }
  
  #resultado <- resultado %>% arrange(desc(r), desc(R2))
  return(resultado)
}

rslt_ruidos_outliers <- ruidos_outliers(enem.df_numeric)
rslt_ruidos_outliers

```


## Amostragem e técnicas de imputação

Vamos selecionar 30% das amostras que não contém valores faltantes no dataset usando as funções `drop_na` e `sample_frac`. Em seguida, vamos selecionar a coluna `NU_NOTA_CH`, com as notas de ciências humanas, para realizar a imputação e comparação com diferentes métodos. Para a inserção de valores NA, vamos utilizar a função `rbinom` para acessar 2% dos valores através de uma distribuição de Bernoulli e trocá-los por NA.

```{r}
set.seed(42)

amostragem <- drop_na(enem.df) %>%
  sample_frac(0.3) %>%
  mutate(NOTA_NA = NU_NOTA_CH)
  amostragem$NOTA_NA[rbinom(nrow(amostragem), 1, 0.02) == 1] <- NA

valores_na <- is.na(amostragem$NOTA_NA)
sum(valores_na == TRUE)
```

Para as técnicas de imputação, vamos analisar as seguintes estratégias:
- Média
- Mediana
- Aleatória
- Regressão linear
- Hotdeck

```{r}
# Média

media <- mean(amostragem$NOTA_NA, na.rm = TRUE)

amostragem <- mutate(amostragem, NOTA_CH_MEAN = NOTA_NA)

amostragem$NOTA_CH_MEAN[is.na(amostragem$NOTA_CH_MEAN)] <- media
```

```{r}
# Mediana

mediana <- median(amostragem$NOTA_NA, na.rm = TRUE)

amostragem <- mutate(amostragem, NOTA_CH_MEDIAN = NOTA_NA)

amostragem$NOTA_CH_MEDIAN[is.na(amostragem$NOTA_CH_MEDIAN)] <- mediana
```

```{r}
# Aleatória

amostragem <- mutate(amostragem, NOTA_CH_RANDOM = NOTA_NA)

amostragem$NOTA_CH_RANDOM[is.na(amostragem$NOTA_CH_RANDOM)] <- runif(1, 0, 1000)
```

Para a regressão linear, vamos utilizar as notas nas outras provas como fixas e deixar a nota em Ciências Humanas como variável.

```{r}
# Regressão linear
amostragem <- mutate(amostragem, NOTA_CH_REGRESSAO = NOTA_NA)

linear <- lm(NOTA_CH_REGRESSAO ~ NU_NOTA_LC + NU_NOTA_MT + NU_NOTA_CN + NU_NOTA_REDACAO, data=amostragem)

for (i in 1:nrow(amostragem)) {
  if(is.na(amostragem$NOTA_CH_REGRESSAO[i])) {
    nota <- linear$coefficients[1] + 
      linear$coefficients[2]*amostragem$NU_NOTA_LC[i] + 
      linear$coefficients[3]*amostragem$NU_NOTA_MT[i] + 
      linear$coefficients[4]*amostragem$NU_NOTA_CN[i] + 
      linear$coefficients[5]*amostragem$NU_NOTA_REDACAO[i]
    
    amostragem$NOTA_CH_REGRESSAO[i] <- nota
  }
}
```

```{r}
amostragem <- mutate(amostragem, NOTA_CH_HOTDECK = NOTA_NA)

hotdeck_impute <- select(amostragem, NU_NOTA_LC, NU_NOTA_MT,
                         NU_NOTA_CN, NU_NOTA_REDACAO, NOTA_CH_HOTDECK) %>%
  hotdeck("NOTA_CH_HOTDECK")

amostragem$NOTA_CH_HOTDECK <- hotdeck_impute$NOTA_CH_HOTDECK
```

### Análise dos resultados

```{r}
cor_media <- cor_fun(amostragem$NU_NOTA_CH, amostragem$NOTA_CH_MEAN)
cor_mediana <- cor_fun(amostragem$NU_NOTA_CH, amostragem$NOTA_CH_MEDIAN)
cor_aleatoria <- cor_fun(amostragem$NU_NOTA_CH, amostragem$NOTA_CH_RANDOM)
cor_regressao <- cor_fun(amostragem$NU_NOTA_CH, amostragem$NOTA_CH_REGRESSAO)
cor_hotdeck <- cor_fun(amostragem$NU_NOTA_CH, amostragem$NOTA_CH_HOTDECK)

cor_names <- c("Média", "Mediana", "Aleatória", "Regressão", "Hotdeck")
cor_values <- c(cor_media, cor_mediana, cor_aleatoria, cor_regressao, cor_hotdeck)

analise_imputacao <- data.frame(cor_names, cor_values)
analise_imputacao[order(analise_imputacao$cor_values, decreasing = TRUE),]

```

A partir da análise, obtemos um valor de correlação acima de 99% para as imputações por média, mediana e regressão, sendo que o maior valor foi para a regressão linear, o que indica que, para esses dados e nessas condições, este é o melhor método.

## Redução de dados

Como nosso dataset possui diversos atributos categórico e textuais, vamos reutilizar a variável `enem.df_numeric` das primeiras etapas, que seleciona apenas as colunas numéricas da base de dados.

```{r}
enem.df_pca <- as.data.frame(enem.df %>% select(where(is.numeric), -NU_ANO, -NU_INSCRICAO))
# summary(prcomp(na.omit(enem.df_pca), center = TRUE, scale. = TRUE))

# Error in prcomp.default(na.omit(enem.df_pca), center = TRUE, scale. = TRUE) : 
# cannot rescale a constant/zero column to unit variance
```

O comando retorna um erro relacionado à divisão por 0 no processo de escala e, por isso, foi comentado para não gerar problemas na execução dos chunks. Uma ideia para entender o que está acontecendo é verificar se temos atributos com variância 0 no dataset.

```{r}
which(apply(na.omit(enem.df_pca), 2, var)==0)
```
Ou seja, esses atributos não possuem variância e podem atrapalhar nossa análise, além de impossibilitar uma escala na exibição do gráfico - o que gera a divisão por 0 e o erro do prcomp.

```{r}
enem.df_pca <- select(enem.df_pca, -TP_ST_CONCLUSAO, -TP_ANO_CONCLUIU,
                          -IN_TREINEIRO, -TP_PRESENCA_CH, -TP_PRESENCA_CN,
                          -TP_PRESENCA_LC, -TP_PRESENCA_MT)

pca <-prcomp(na.omit(enem.df_pca), scale. = TRUE, center = TRUE)
summary(pca)
```
```{r}
ggbiplot(pca, alpha=0)
```

### Análise do PCA

Podemos visualizar que o PCA passa de 70% só do componente 9 e só atinge 90% no 14º componente. Nessas condições e considerando o tamanho do dataset utilizado, o PCA pode não ser a melhor ferramenta para redução de dimensionalidade.  
Podemos pensar em outras formas de análise, como MDS, porém esta não é possível dada a dimensão do dataset.

```{r}
# cmdscale(dist(enem.df_pca), eig=TRUE, k=2)

# Error: cannot allocate vector of size 149.0 Gb
```

### Referências

-   <https://rstudio-pubs-static.s3.amazonaws.com/558925_38b86f0530c9480fad4d029a4e4aea68.html#calculating-cramers-v-in-r>
-   <https://statsandr.com/blog/outliers-detection-in-r>
