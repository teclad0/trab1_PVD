---
title: "Trabalho final"
output: html_document
date: '2022-04-01'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Universidade Federal de São Carlos

## Bacharelado em Ciência da Computação

Processamento e Visualização de Dados\
Professor: Anderson Chaves Carniel

Estudantes:\
Hemilyn Stephanye Aguiar Porfirio - RA 759392\
Igor Lúcio Manta Guedes - RA 743185

# Descrição do conjunto

O conjunto contém os dados de realização do Exame Nacional do Ensino Médio, aplicado nos dias 17 e 24 de janeiro de 2021 (por conta da pandemia de coronavírus). Também houve, pela primeira vez, a aplicação digital da prova, em 31 de janeiro e 07 de fevereiro, além da segunda aplicação para Pessoas Privadas de Liberdade, em 24 e 25 de fevereiro.

No total, existem 76 atributos e 5783109 linhas, contemplando dados de inscrição anonimizados, locais de realização da prova, pontuações e questionário socioeconômico (aplicado na etapa de inscrição). Por conta do grande número de atributos e descrições, o arquivo com o dicionário está disponibilizado neste link com acesso pelo email institucional da UFSCar: <https://drive.google.com/file/d/1BjBYUCjRMX78L6ddpWAI8tfIrIjMzuK8/view?usp=sharing>

Os dados foram obtidos através da plataforma oficial do Governo Federal e podem ser acessados em: <https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados/enem>

# Inicialização

```{r echo=T, results='hide'}
library(tidyverse)
library(data.table)
library(rcompanion)
library(lsr)
library(vcd)
library(outliers)
library(EnvStats)
library(DescTools)
library(VIM)
library(ggbiplot)

options(scipen = 999)

```

# Importação

Considerando que o dataset completo possui cerca de 2GB de dados, foram carregadas apenas as 200.000 primeiras linhas, já que o dataset inteiro pode não caber em memória em diversas máquinas e torna o processamento extramente custoso.

```{r}
file <- 'enem/DADOS/MICRODADOS_ENEM_2020.csv'
enem.df <- fread(input=file,
           integer64='character',
           encoding = "Latin-1",
           quote = FALSE,
           na.strings = "",
           nrows=200000)

head(enem.df)
```

# Pré-Processamento

## Verificação de possíveis atributos redundantes

Para o cálculo de covariância, é necessário dropar a coluna **NU_ANO** que possui o valor constante 2022 e tratar casos com desvio padrão 0 e com valores NA.

```{r}
enem.df <- subset(enem.df, select = -NU_ANO)
```

### Atributos numéricos

```{r}
enem.df_numeric <- as.data.frame(enem.df %>% select(where(is.numeric)))

cor_fun <- function(x, y) {
  val <- tryCatch(cor(x, y, use="complete.obs"), error = function(e) e, warning = function(w) w)
  if (any(class(val) %in% c("simpleWarning", "warning"))) {
    return(mean(x))
  } else {
    return(val)
  }
}

medidas <- function(vetor1, vetor2) {
  corr_medida <- cor_fun(vetor1, vetor2)
  det_medida <- cor_fun(vetor1, vetor2)^2
  lista_medidas <-
    list("correlacao" = corr_medida, "determinacao" = det_medida)
  lista_medidas
}

calculo_redundante <- function(dados){
  resultado <- tibble(
  colu1= character(),
  colu2= character(),
  r= numeric(),
  R2=numeric()
  )
  for (col1 in colnames(dados)) {
    for (col2 in colnames(dados)) {
      if (col1 == col2) {
        next
      }
      li_med <- medidas(dados[, col1], dados[, col2])

      #print(paste(col1,"::",col2))
      
      # Retornar apenas atributos com valores relevantes
      if (!is.na(li_med$correlacao) & !is.na(li_med$determinacao)) {
        if (li_med$correlacao > 0.7 |
          li_med$correlacao < -0.7 |
          li_med$determinacao > 0.7) {
          resultado <- add_row(resultado,
            colu1 = col1, colu2 = col2,
            r = li_med$correlacao,
            R2 = li_med$determinacao
          )
        }
      }
    }
  }
  resultado <- resultado[
    !duplicated(
      apply(resultado, 1, function(x) paste(sort(x), collapse = ""))
    ),
  ]

  resultado <- resultado %>% arrange(desc(r), desc(R2))
  return(resultado)
}

resultado <- calculo_redundante(enem.df_numeric)
resultado

```

Através do resultado, é possível observar que os atributos TP_PRESENCA_CH e TP_PRESENCA_LC, TP_PRESENCA_MT e TP_PRESENCA_CN possuem r e R² iguais a um. Isso significa que todos os valores são exatamente iguais. Essa situação faz sentido pois as provas de linguagens e códigos e ciências humanas, e ciências da natureza e matemática são realizadas no mesmo dia, assim como as outras presenças, pois é bem provavél que se a pessoa foi para o primeiro dia de prova ela também vai para o segundo dia de prova, senão a prova é anulada.

Além disso, os atributos CO_MUNICIPIO_PROVA e CO_UF_PROVA, CO_MUNICIPIO_ESC e CO_UF_ESC, CO_PROVA_CH CO_PROVA_LC, CO_PROVA_CN CO_PROVA_MT possuem um valor bem próximo de 1 , sendo 0.99 para o r e 0.99 para o R². Isso se deve ao fato de que o código do município sempre contém o código da UF em que a prova foi realizada, como pode ser visto abaixo:

```{r}
head(enem.df$CO_MUNICIPIO_PROVA)
head(enem.df$CO_UF_PROVA)

```

### Atributos categóricos

[ ]explicar rapidamente o coeficiente cramer [ ]explicar pq as tx_resposta\* foram retiradas

```{r}
enem.df_character <- enem.df %>%
  select(where(is.character), -NU_INSCRICAO, -TX_RESPOSTAS_CN, -TX_RESPOSTAS_CH, -TX_RESPOSTAS_LC, -TX_RESPOSTAS_MT) 


cramers_v <- function(dados){
  rslt <- tibble(
  colu1= character(),
  colu2= character(),
  cramer = numeric()
   )
  
   for (col1 in colnames(dados)) {
    for(col2 in colnames(dados)){
      if (col1 != col2) {
        
      c <- CramerV(unlist(dados[,..col1]), unlist(dados[,..col2]), useNA="ifany")
            if( c > 0.7){
              rslt <- add_row(rslt, colu1=col1, colu2=col2, cramer=c)}
      }
      }
      }
  rslt<- rslt[!duplicated(apply(rslt,1,function(x) paste(sort(x),collapse=''))),]
  rslt <- rslt %>% arrange(desc(cramer))
  rslt
}

rlt_cramer <-  cramers_v(enem.df_character)
rlt_cramer
```

Observa-se no resultado que os atributos TX_GABARITO possuem o valor de coeficiente exatamente 1, isso se dá pois esse atributo é um vetor com as respostas de cada tipo prova e as provas de ciências da natureza e matemática são realizadas juntas, assim como as provas de linguagens e códigos e ciências humanas.

### Conclusão

Os coeficientes utilizados nos ajudaram a entender os relacionamentos e associações existentes nesse conjunto de dados, dessa forma encontramos atributos que são redundantes e podem ser removidos sem prejudicar o conjunto de dados. São esses atributos:

-   TP_PRESENCA_CH mesma compatibilidade com TP_PRESENCA_MT, TP_PRESENCA_CN e TP_PRESENCA_LC
-   CO_MUNICIPIO_PROVA contém CO_UF_PROVA
-   CO_MUNICIPIO_ESC e CO_UF_ESC,
-   CO_PROVA_CH e CO_PROVA_LC,
-   CO_PROVA_CN e CO_PROVA_MT,
-   CO_MUNICIPIO_PROVA e CO_MUNICIPIO_ESC
-   TX_GABARITO_CN mesma compatibilidade com TX_GABARITO_MT\
-   TX_GABARITO_CH mesma compatibiilidade com TX_GABARITO_LC
-   SG_UF_PROVA e SG_UF_ESC

```{r}
enem.df <- subset(enem.df, select = -c(TP_PRESENCA_MT, TP_PRESENCA_CN, TP_PRESENCA_LC, CO_UF_PROVA, CO_UF_ESC, CO_PROVA_LC, CO_PROVA_MT, CO_MUNICIPIO_ESC, TX_GABARITO_MT, TX_GABARITO_LC, SG_UF_ESC))

enem.df_numeric <- subset(enem.df_numeric, select = -c(TP_PRESENCA_MT, TP_PRESENCA_CN, TP_PRESENCA_LC, CO_UF_PROVA, CO_UF_ESC, CO_PROVA_LC, CO_PROVA_MT, CO_MUNICIPIO_ESC))
```

## Normalização

A normalização será realizada nos atributos NU_NOTA_CH e NU_NOTA_MT que representam, respectivamente, a nota da prova de ciências humanas e a nota de redação. O conjunto de dados possui diversos atributos sem significado semantico(n sei se eh essa a palavra), que apresentam um significado específico, como código de provas e código de municipio.

### Aplicação no atributos NU_NOTA_CH e NU_NOTA_MT

No bloco abaixo, as funções z score e min-max são aplicadas nos atributos escolhidos e os resultados são adicionados a um novo conjunto, chamado *enem.df_numeric_norm*, derivado do conjunto original.

```{r}
head(enem.df_numeric,50)
options(scipen = 999) 

z_score_norm <- function(x) {
  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)
}
min_max_norm <- function(x, min = 0, max = 1) {
  num <- (x - min(x, na.rm = TRUE)) * (max - min)
  denom <- max(x, na.rm = TRUE) - min(x, na.rm = TRUE)

  min + num / denom
}

NU_NOTA_CH_normz <- z_score_norm(enem.df$NU_NOTA_CH)
NU_NOTA_CH_norm01 <- min_max_norm(enem.df$NU_NOTA_CH)
NU_NOTA_MT_normz <- z_score_norm(enem.df$NU_NOTA_MT)
NU_NOTA_MT_norm01 <- min_max_norm(enem.df$NU_NOTA_MT)

# Colocar do numerico pq vai precisar rodar o r e R²
enem.df_numeric_norm <- enem.df_numeric %>%
  select(-NU_NOTA_CH, -NU_NOTA_MT) %>%
  mutate(
    NU_NOTA_CH_normz, NU_NOTA_CH_norm01,
    NU_NOTA_MT_normz, NU_NOTA_MT_norm01
  )


head(enem.df_numeric_norm)
```

A seguir são realizados testes para analisar os efeitos da normalização com os atributos redundantes.

### Efeitos normalização

```{r}

# Teste de redundância dos atributos numéricos normalizados no conjunto 

calculo_redundante_norm <- function(dados) {
  resultado <- tibble(
    colu1 = character(),
    colu2 = character(),
    r = numeric(),
    R2 = numeric()
  )

  # for (col1 in colnames(dados)) {
  for (col1 in
    c(
      "NU_NOTA_CH_normz", "NU_NOTA_CH_norm01",
      "NU_NOTA_MT_normz", "NU_NOTA_MT_norm01"
  )) {
    for (col2 in colnames(dados)) {
      if (col1 == col2) {
        next
      }

      li_med <- medidas(dados[, col1], dados[, col2])

      if (!is.na(li_med$correlacao) & !is.na(li_med$determinacao)) {
        resultado <- add_row(resultado,
          colu1 = col1, colu2 = col2,
          r = li_med$correlacao, R2 = li_med$determinacao
        )
      }
    }
  }
  resultado <- resultado[
    !duplicated(
      apply(resultado, 1, function(x) paste(sort(x), collapse = ""))
    ),
  ]
  resultado <- resultado %>% arrange(desc(r), desc(R2))
  return(resultado)

  }

rlt_redun_norms <- calculo_redundante_norm(enem.df_numeric_norm)
head(rlt_redun_norms)

```

Testes realizados com o dataset original

```{r}
# Teste com atributos numéricos realizado no conjunto com os atributos originais, apenas observando o comportamento em comparação aos atributos escolhidos

calculo_redundante_notas <- function(dados) {
  resultado <- tibble(
    colu1 = character(),
    colu2 = character(),
    r = numeric(),
    R2 = numeric()
  )

  for (col1 in c("NU_NOTA_CH", "NU_NOTA_MT")) {
    for (col2 in colnames(dados)) {
      if (col1 == col2) {
        next
      }

      li_med <- medidas(dados[, col1], dados[, col2])
      if (!is.na(li_med$correlacao) & !is.na(li_med$determinacao)) {
        resultado <- add_row(resultado,
          colu1 = col1, colu2 = col2,
          r = li_med$correlacao, R2 = li_med$determinacao
        )
      }
    }
  }
  resultado <- resultado[
    !duplicated(
      apply(resultado, 1, function(x) paste(sort(x), collapse = ""))
    ),
  ]
  resultado <- resultado %>% arrange(desc(r), desc(R2))
  return(resultado)
}

rlt_redun_original <- calculo_redundante_notas(enem.df_numeric)
head(rlt_redun_original)

```

### Conclusão

Concluí-se que o uso das normalizações manteve o mesmo significado dos coeficientes quando comparado ao uso dos dados originais

## Manipulação de dados faltantes

Primeiramente, vamos analisar o nosso dataset para encontrar quais e quantos são os dados faltantes:

```{r}
# conta a quantidade de dados NA
na_count <- colSums(is.na(enem.df)) %>%
  as.data.frame() %>%
  mutate(field = colnames(enem.df))

names(na_count) <- c("count", "field")

na_count <- filter(na_count, count > 0) %>%
  mutate(percentage = count * 100 / nrow(enem.df)) %>%
  select(-count) %>%
  arrange(desc(percentage))

na_count
```

Apesar de incrivelmente alto, esse número condiz com os dados do INEP, que afirma que em torno de 48% dos inscritos não compareceram à prova. Vale lembrar que essa aplicação ocorreu em janeiro de 2021, época em que a pandemia de coronavírus ainda era severa no Brasil. Ainda assim, uma quantidade muito significativa de 78% dos dados relacionados ao local de aplicação não estão disponíveis, não sabemos o motivo.\
Como a maioria desses dados serve para identificação do local de aplicação, vamos focar na imputação do questionário socioeconômico, já que há linhas onde as pessoas compareceram à prova mas não responderam ao questionário. Dessa forma, também pretendemos reduzir um possível enviesamento ao imputar uma quantidade tão grande de dados.\
Utilizaremos as questões de 1 a 6 para realizar o tratamento de dados faltantes. Por serem atributos que servem para identificar questões sociais e econômicas de um indivíduo, entendemos que uma abordagem baseada em tendência central pode não ser tão precisa, considerando a complexidade das análises que podem ser feitas a partir do dataset.\
Sendo assim, vamos utilizar a imputação por HotDeck, disponibilizada no pacote VIM. Nas próximas seções, veremos que esse método obteu um resultado razoável e possui uma execução rápida. Métodos como regressão linear e kNN impute tornam-se inviáveis pelo tamanho do dataset.

```{r}
# Não é possível aplicar o algoritmo kNN
# kNN(enem.df, "Q005")
# Error: cannot allocate vector of size 24.0 Gb

enem.df <- hotdeck(enem.df, c("Q001", "Q002", "Q003", "Q004", "Q005", "Q006"), imp_var = FALSE)
head(enem.df)
```

## Manipulação de dados ruídosos e outliers

dixon so funciona para ate 20 observaçeos

Verificando se existe algum valor que distoa dos dados aceitos para cada coluna numérica

```{r}
uniq.df <- function(dados){
     for (col in colnames(dados)) {
      li <- unique(dados[,col])
      print(col)
      print(li)
        
      }
}
uniq.df(enem.df_numeric)

```

Todos os atributos estão dentro dos valores aceitos de cada atributo.

```{r}
# removendo binario e codigos
enem.df_numeric_out <- enem.df_numeric %>% select(-CO_MUNICIPIO_PROVA, -CO_PROVA_CN, -CO_PROVA_CH, -TP_LINGUA, -IN_TREINEIRO, -TP_LOCALIZACAO_ESC, -TP_PRESENCA_CH)

quant <- function(dados){
   resultado <- tibble(
      atr = character(),
      min = numeric(),
      max = numeric()
    )
  for (col in colnames(dados)){
    
    lim_min <- quantile(dados[,col], .01, na.rm=TRUE)
    lim_max <- quantile(dados[,col], .99, na.rm=TRUE)
    
    resultado <- add_row(resultado, atr= col, min= lim_min, max= lim_max)
  }
  return(resultado)
}

rst_quant <- quant(enem.df_numeric_out)

out_grub_rosner <- function(dados) {
  resultado <- tibble(
    atr = character(),
    grubb_p = numeric(),
    grubb_v = character(),
    rosner_v = numeric(),
    rosner_out = logical()

  )
  for (col1 in colnames(dados)) {
    r <- rosnerTest(unlist(dados[,col1]), k=1, warn=FALSE)
    r_v <- r$all.stats$Value
    r_o <- r$all.stats$Outlier
    
    g <- grubbs.test(unlist(dados[,col1]))
    g_p <- g$p.value
    g_v <- g$alternative
    
    resultado <- add_row( resultado,atr= col1, grubb_p = g_p, grubb_v = g_v, rosner_v = r_v, rosner_out = r_o)
  }
  return(resultado)
}

rslt_out_grub_rosner <- out_grub_rosner(enem.df_numeric_out)

rst_quant
rslt_out_grub_rosner

```

### Análise dos resultados

Vantagens de cada método:

Desvantagens de cada método:

## Amostragem e técnicas de imputação

Vamos selecionar 30% das amostras que não contém valores faltantes no dataset usando as funções `drop_na` e `sample_frac`. Em seguida, vamos selecionar a coluna `NU_NOTA_CH`, com as notas de ciências humanas, para realizar a imputação e comparação com diferentes métodos. Para a inserção de valores NA, vamos utilizar a função `rbinom` para acessar 2% dos valores através de uma distribuição de Bernoulli e trocá-los por NA.

```{r}
set.seed(42)

amostragem <- drop_na(enem.df) %>%
  sample_frac(0.3) %>%
  mutate(NOTA_NA = NU_NOTA_CH)
  amostragem$NOTA_NA[rbinom(nrow(amostragem), 1, 0.02) == 1] <- NA

valores_na <- is.na(amostragem$NOTA_NA)
sum(valores_na == TRUE)
```

Para as técnicas de imputação, vamos analisar as seguintes estratégias: - Média - Mediana - Aleatória - Regressão linear - Hotdeck

```{r}
# Média

media <- mean(amostragem$NOTA_NA, na.rm = TRUE)

amostragem <- mutate(amostragem, NOTA_CH_MEAN = NOTA_NA)

amostragem$NOTA_CH_MEAN[is.na(amostragem$NOTA_CH_MEAN)] <- media
```

```{r}
# Mediana

mediana <- median(amostragem$NOTA_NA, na.rm = TRUE)

amostragem <- mutate(amostragem, NOTA_CH_MEDIAN = NOTA_NA)

amostragem$NOTA_CH_MEDIAN[is.na(amostragem$NOTA_CH_MEDIAN)] <- mediana
```

```{r}
# Aleatória

amostragem <- mutate(amostragem, NOTA_CH_RANDOM = NOTA_NA)

amostragem$NOTA_CH_RANDOM[is.na(amostragem$NOTA_CH_RANDOM)] <- runif(1, 0, 1000)
```

Para a regressão linear, vamos utilizar as notas nas outras provas como fixas e deixar a nota em Ciências Humanas como variável.

```{r}
# Regressão linear
amostragem <- mutate(amostragem, NOTA_CH_REGRESSAO = NOTA_NA)

linear <- lm(NOTA_CH_REGRESSAO ~ NU_NOTA_LC + NU_NOTA_MT + NU_NOTA_CN + NU_NOTA_REDACAO, data=amostragem)

for (i in 1:nrow(amostragem)) {
  if(is.na(amostragem$NOTA_CH_REGRESSAO[i])) {
    nota <- linear$coefficients[1] + 
      linear$coefficients[2]*amostragem$NU_NOTA_LC[i] + 
      linear$coefficients[3]*amostragem$NU_NOTA_MT[i] + 
      linear$coefficients[4]*amostragem$NU_NOTA_CN[i] + 
      linear$coefficients[5]*amostragem$NU_NOTA_REDACAO[i]
    
    amostragem$NOTA_CH_REGRESSAO[i] <- nota
  }
}
```

```{r}
amostragem <- mutate(amostragem, NOTA_CH_HOTDECK = NOTA_NA)

hotdeck_impute <- select(amostragem, NU_NOTA_LC, NU_NOTA_MT,
                         NU_NOTA_CN, NU_NOTA_REDACAO, NOTA_CH_HOTDECK) %>%
  hotdeck("NOTA_CH_HOTDECK")

amostragem$NOTA_CH_HOTDECK <- hotdeck_impute$NOTA_CH_HOTDECK
```

### Análise dos resultados

```{r}
cor_media <- cor_fun(amostragem$NU_NOTA_CH, amostragem$NOTA_CH_MEAN)
cor_mediana <- cor_fun(amostragem$NU_NOTA_CH, amostragem$NOTA_CH_MEDIAN)
cor_aleatoria <- cor_fun(amostragem$NU_NOTA_CH, amostragem$NOTA_CH_RANDOM)
cor_regressao <- cor_fun(amostragem$NU_NOTA_CH, amostragem$NOTA_CH_REGRESSAO)
cor_hotdeck <- cor_fun(amostragem$NU_NOTA_CH, amostragem$NOTA_CH_HOTDECK)

cor_names <- c("Média", "Mediana", "Aleatória", "Regressão", "Hotdeck")
cor_values <- c(cor_media, cor_mediana, cor_aleatoria, cor_regressao, cor_hotdeck)

analise_imputacao <- data.frame(cor_names, cor_values)
analise_imputacao[order(analise_imputacao$cor_values, decreasing = TRUE),]

```

A partir da análise, obtemos um valor de correlação acima de 99% para as imputações por média, mediana e regressão, sendo que o maior valor foi para a regressão linear, o que indica que, para esses dados e nessas condições, este é o melhor método.

## Redução de dados

Como nosso dataset possui diversos atributos categórico e textuais, vamos reutilizar a variável `enem.df_numeric` das primeiras etapas, que seleciona apenas as colunas numéricas da base de dados.

```{r}
enem.df_pca <- as.data.frame(enem.df %>% select(where(is.numeric), -NU_ANO, -NU_INSCRICAO))
# summary(prcomp(na.omit(enem.df_pca), center = TRUE, scale. = TRUE))

# Error in prcomp.default(na.omit(enem.df_pca), center = TRUE, scale. = TRUE) : 
# cannot rescale a constant/zero column to unit variance
```

O comando retorna um erro relacionado à divisão por 0 no processo de escala e, por isso, foi comentado para não gerar problemas na execução dos chunks. Uma ideia para entender o que está acontecendo é verificar se temos atributos com variância 0 no dataset.

```{r}
which(apply(na.omit(enem.df_pca), 2, var)==0)
```

Ou seja, esses atributos não possuem variância e podem atrapalhar nossa análise, além de impossibilitar uma escala na exibição do gráfico - o que gera a divisão por 0 e o erro do prcomp.

```{r}
enem.df_pca <- select(enem.df_pca, -TP_ST_CONCLUSAO, -TP_ANO_CONCLUIU,
                          -IN_TREINEIRO, -TP_PRESENCA_CH, -TP_PRESENCA_CN,
                          -TP_PRESENCA_LC, -TP_PRESENCA_MT)

pca <-prcomp(na.omit(enem.df_pca), scale. = TRUE, center = TRUE)
summary(pca)
```

```{r}
ggbiplot(pca, alpha=0)
```

### Análise dos resultados

Podemos visualizar que o PCA passa de 70% só do componente 9 e só atinge 90% no 14º componente. Nessas condições e considerando o tamanho do dataset utilizado, o PCA pode não ser a melhor ferramenta para redução de dimensionalidade.\
Podemos pensar em outras formas de análise, como MDS, porém esta não é possível dada a dimensão do dataset.

```{r}
# cmdscale(dist(enem.df_pca), eig=TRUE, k=2)

# Error: cannot allocate vector of size 149.0 Gb (!!!)
```

# Visualização dos dados

```{r}
conj_1 <- enem.df

ggplot(conj_1) +
  geom_histogram(aes(x= TP_PRESENCA_CH, fill=Q024), position = position_dodge(), stat="count")

```

**Questão 2:** Qual a média de desempenho na prova por cor/raça declarada?\
Vamos utilizar um boxplot para analisar, além da média, a distribuição de pontuações para cada cor/raça declarada no momento da inscrição da prova. Para isso, também vamos criar uma função para calcular a média das 4 provas e redação, o que significa que apenas poderemos usar os participantes que compareceram à prova.

```{r}
# filtro pelos candidatos presentes na prova
# e seleção apenas dos atributos de interesse
notas_cor_raca <- filter(enem.df, TP_PRESENCA_CN == 1 &
                    TP_PRESENCA_CH == 1 & TP_STATUS_REDACAO == 1) %>%
                  select(NU_NOTA_CN, NU_NOTA_CH, NU_NOTA_LC,
                    NU_NOTA_MT, NU_NOTA_REDACAO, TP_COR_RACA)

# rotulando dados categóricos
notas_cor_raca$TP_COR_RACA <- factor(notas_cor_raca$TP_COR_RACA,
                                levels = c(0,1,2,3,4,5,6),
                                labels=c('Não declarado',
                                'Branca','Preta',
                                'Parda','Amarela',
                                'Indígena',
                                'Não dispõe da informação'))

# função de média simples para a prova
enem_mean <- function(CN, CH, LC, MT, RD) {
  (CN+CH+LC+MT+RD)/5
}

# conjunto contendo apenas média e raça
dados_PLOT2 <- summarise(notas_cor_raca, "Cor/Raça" = TP_COR_RACA,
                      "Nota média" = enem_mean(NU_NOTA_CN,
                      NU_NOTA_CH, NU_NOTA_LC, NU_NOTA_MT, NU_NOTA_REDACAO))

media_geral <- mean(dados_PLOT2$`Nota média`)

# boxplot com uma linha na direção da média geral da prova
ggplot(data = dados_PLOT2) +
  geom_boxplot(outlier.size=.7, mapping = aes(x = `Cor/Raça`, y = `Nota média`)) +
  geom_hline(yintercept = media_geral, color = "blue")
```

**Questão 3:** Qual a proporção entre candidatos presentes e ausentes na prova por faixa de renda mensal?\
Nessa questão, utilizaremos o inverso da questão anterior - apenas os dados com TP_PRESENCA = 0, lembrando que a informação sobre renda familiar encontra-se na questão 006 do formulário socioeconômico.

```{r}
# removendo candidatos eliminados da prova para melhorar a visualização
presenca_renda <- filter(enem.df, TP_PRESENCA_CN < 2 & TP_PRESENCA_CH < 2 &
                         TP_PRESENCA_LC < 2 & TP_PRESENCA_CH < 2) %>%
                  select(TP_PRESENCA_CN, Q006)

# rotulando dados categóricos
presenca_renda$TP_PRESENCA_CN <- factor(presenca_renda$TP_PRESENCA_CN, levels = c(0,1),
                                    labels=c('Faltou à prova',
                                             'Presente na prova'))

# rotulando dados categóricos
presenca_renda$Q006 <- factor(presenca_renda$Q006,levels =  c('A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q'),
                         labels=c('Nenhuma renda.',
                                  'Até R$ 1.045,00',
                                  'De R$ 1.045,01 até R$ 1.567,50',
                                  'De R$ 1.567,51 até R$ 2.090,00',
                                  'De R$ 2.090,01 até R$ 2.612,50',
                                  'De R$ 2.612,51 até R$ 3.135,00',
                                  'De R$ 3.135,01 até R$ 4.180,00',
                                  'De R$ 4.180,01 até R$ 5.225,00',
                                  'De R$ 5.225,01 até R$ 6.270,00',
                                  'De R$ 6.270,01 até R$ 7.315,00',
                                  'De R$ 7.315,01 até R$ 8.360,00',
                                  'De R$ 8.360,01 até R$ 9.405,00',
                                  'De R$ 9.405,01 até R$ 10.450,00',
                                  'De R$ 10.450,01 até R$ 12.540,00',
                                  'De R$ 12.540,01 até R$ 15.675,00',
                                  'De R$ 15.675,01 até R$ 20.900,00',
                                  'Acima de R$ 20.900,00'))

# plot de histograma separando dados por renda familiar
ggplot(presenca_renda) +
  geom_histogram(aes(x= TP_PRESENCA_CN, fill=Q006), position = position_dodge(), stat="count") +
  labs(x = "Presença", y = "Candidatos")
```

**Questão 4:** [TODO Igor]

# Referências

-   <https://rstudio-pubs-static.s3.amazonaws.com/558925_38b86f0530c9480fad4d029a4e4aea68.html#calculating-cramers-v-in-r>
-   <https://statsandr.com/blog/outliers-detection-in-r>
